---
title: "Nanostring GeoMx analysis"
author: "Ies Nijman"
output: 
  html_document:
    code_download: true
    code_folding: hide
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: true
    toc_depth: 3
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

![](C:/Users/pkloosterman/Documents/general_workflow/USEQ-logo-subtitle.jpg)

# Klant: Useq

# Project: Organ atlas

# Dataset: Kidney data

**date: `r format(Sys.time(), '%H %M %a %d %B, %Y')`**

![](C:/Users/pkloosterman/Documents/general_workflow/decoration-stroke-flat-v2.png)

**loading dependencies** Please make sure the following packages are
installed and required libraries can be loaded: \*
install.packages("pkgbuild") // pkgbuild::check_build_tools() \*
install.packages("devtools") \*
devtools::install_github("Nanostring-Biostats/NanoStringNCTools") \*
devtools::install_github("Nanostring-Biostats/GeomxTools", ref = "dev")
\* devtools::install_github("Nanostring-Biostats/GeoMxWorkflows", ref =
"main") \* BiocManager::install("GeoMxWorkflows") \*
devtools::install_github("DavisLaboratory/standR") \*
BiocManager::install("SpatialDecon") \* BiocManager::install("GSVA") \*
install.packages("plotly") \* install.packages("DT") \*
install.packages("msigdbr") #install.packages("digest")
#install.packages("rmarkdown") #install.packages("kable")

```{r load_libraries, message=FALSE, warning=FALSE}

#load libraries
library(NanoStringNCTools)
library(GeomxTools)
library(GeoMxWorkflows)
library(SpatialDecon)
library(GSVA) #for pathway analyses
library(msigdbr) #for molecular signatures in pathway analyses
library(knitr)
library(dplyr)
library(ggforce)
library(ggplot2)
library(scales) # for percent
library(reshape2)  # for melt
library(cowplot)   # for plot_grid
library(umap)
library(Rtsne)
library(pheatmap)  # for pheatmap
library(ggrepel) 
library(scales) #for ggplot peaudolog to prevent errors on log(0)
library(DT)
library(plotly)
library(gridExtra)
library(RColorBrewer)

library(limma)
library(clusterProfiler) #pathway analysis
library(gage)
```

# 1 loading base files

```{r loading_base_data}
# Reference the main folder 'file.path' containing the sub-folders with each data file type:

datadir<-file.path("C:/Users/pkloosterman/Documents/general_workflow/Kidney_Dataset")
#datadir<-file.path("C:/Users/pimkl/OneDrive/Documenten/UMCU/R/general_workflow/Kidney_Dataset/")
```

To locate a specific file path replace the above line with datadir \<-
file.path("\~/Folder/SubFolder/DataLocation") replace the Folder,
SubFolder, DataLocation as needed. The DataLocation folder should
contain a dccs, pkcs, and annotation folder with each set of files
present as needed automatically list files in each directory for use.

**Take care you import a column with nuclei count separately if you
want.**

```{r parse_files}
DCCFiles <- dir(file.path(datadir, "dccs"), pattern = ".dcc$",
                full.names = TRUE, recursive = TRUE)
PKCFiles <- dir(file.path(datadir, "pkcs"), pattern = ".pkc$",
                full.names = TRUE, recursive = TRUE)
SampleAnnotationFile <-
  dir(file.path(datadir, "annotation"), pattern = "^[^~]",
      full.names = TRUE, recursive = TRUE)
```

# 2 load data

```{r load_data}
Data <-
  readNanoStringGeoMxSet(dccFiles = DCCFiles,
                         pkcFiles = PKCFiles,
                         phenoDataFile = SampleAnnotationFile,
                         phenoDataSheet = "Template",
                         phenoDataDccColName = "Sample_ID",
                         protocolDataColNames = c("aoi", "roi"),
                         experimentDataColNames = c("panel"))

#save data to prevent loading time for retakes
saveData<-Data
#Data<-saveData

#change Data column names and manual correction of spelling errors
Data@phenoData@data[["slide_name"]]<-Data@phenoData@data[["slide name"]]
Data@phenoData@data[["slide name"]]<-  NULL
Data@phenoData@data[["ANN4"]]<-gsub("i", "", Data@phenoData@data[["ANN4"]])

#+1 references the slide name column
ann_size<-length(colnames(Data@phenoData@data)[grepl("ANN",colnames(Data@phenoData@data))])+1 
ann_names<-c(colnames(Data@phenoData@data)[grepl("ANN",colnames(Data@phenoData@data))],"slide_name")

# Feel free to change the order of which colors are appointed.
color<-c("#A349A4", "#FFFF33", "#E7298A", "#091833", "#1B9E77", "#D95F02", "#7570B3",  "#66A61E", "#E6AB02", "#8DD3C7", "#9F000F", "#BEBADA", "#FB8072", "#80B1D3", "#FDB462", "#B3DE69", "#FCCDE5", "#D9D9D9", "#BC80BD", "#CCEBC5", "#FFED6F", "#377EB8", "#984EA3", "#4DAF4A", "#FF71CE", "#FF7F00", "#A6CEE3", "#1F78B4", "#B2DF8A", "#33A02C", "#FB9A99", "#E31A1C", "#FDBF6F", "#CAB2D6", "#6A3D9A", "#FFFF99", "#B15928")
show_col(color)

# Use count and count_max to set the range of color needed for each column.
# With setNames() the color code is linked to each unique individual value of each column.
count=1
color_list = list()
for (ann in ann_names) {
  count_max = count+length(unique(Data@phenoData@data[[ann]]))-1
  color_list[[ann]]<-setNames(color[count:count_max], unique(Data@phenoData@data[[ann]]))
  count=count_max+1
}
color_list
```

```{r}
paste("Reads from following runs used: ",unique(pData(protocolData(Data))$SeqSetId))

```

# 3 Study design

```{r annotate}
pkcs <- annotation(Data)
modules <- gsub(".pkc", "", pkcs)
kable(data.frame(PKCs = pkcs, modules = modules))
```

Select the annotations we want to show, use \`\` to surround column
names with spaces or special symbols

```{r select_annotations}
count_mat <- dplyr::count(pData(Data), ANN1,ANN2,ANN3,ANN4,slide_name)
```

Simplify the slide names if required

```{r simplify_names}
count_mat$slide_name <- gsub("disease", "d", gsub("normal", "n", count_mat$slide_name))
count_mat$ANN2 <- gsub("disease", "d", gsub("normal", "n", count_mat$ANN2))
#count_mat$path_ann <- gsub("i", "", count_mat$path_ann) #correcting spelling error
```

Gather the data and plot in order: class, slide name, region, segment

```{r gather_data}
test_gr <- gather_set_data(count_mat, 1:ann_size)
test_gr$x <- factor(test_gr$x, levels = ann_names)
```

Plot Sankey

```{r Sankey_plot, fig.width=20,fig.height=11}
ggplot(test_gr, height = 10, width = 10, aes(x, id = id, split = y, value = n)) +
  geom_parallel_sets(aes(fill = ANN3), alpha = 0.5, axis.width = 0.1) +
  geom_parallel_sets_axes(axis.width = 0.2) +
  geom_parallel_sets_labels(color = "white", size = 5) +
  theme_classic(base_size = 12) + 
  theme(legend.position = "bottom",
        axis.ticks.y = element_blank(),
        axis.line = element_blank(),
        axis.text.y = element_blank()) +
  scale_y_continuous(expand = expansion(0)) + 
  scale_x_discrete(expand = expansion(0)) +
  labs(x = "", y = "") +
  scale_fill_manual(values=color_list$ANN3) +
  annotate(geom = "segment", x = 4.25, xend = 4.25,
           y = 10, yend = 61, lwd = 2) +
  annotate(geom = "text", x = 4.19, y = 25, angle = 90, size = 5,
           hjust = 0.5, label = "50 segments")
```

# 4 QC & Pre-processing

Shift counts to one

```{r shift_counts}
#shift any expression counts with a value of 0 to 1 to enable in downstream transformations.
Data <- shiftCountsOne(Data, useDALogic = TRUE)
```

# 4.1 Segment QC

We first assess sequencing quality and adequate tissue sampling for
every ROI/AOI segment.

Every ROI/AOI segment will be tested for:

Raw sequencing reads: segments with \>1000 raw reads are removed. %
Aligned,% Trimmed, or % Stitched sequencing reads: segments below \~80%
for one or more of these QC parameters are removed. % Sequencing
saturation ([1-deduplicated reads/aligned reads]%): segments below \~50%
require additional sequencing to capture full sample diversity and are
not typically analyzed until improved. Negative Count: this is the
geometric mean of the several unique negative probes in the GeoMx panel
that do not target mRNA and establish the background count level per
segment; segments with low negative counts (1-10) are not necessarily
removed but may be studied closer for low endogenous gene signal and/or
insufficient tissue sampling. No Template Control (NTC) count: values
\>1,000 could indicate contamination for the segments associated with
this NTC; however, in cases where the NTC count is between 1,000-
10,000, the segments may be used if the NTC data is uniformly low (e.g.
0-2 counts for all probes). Nuclei: \>100 nuclei per segment is
generally recommended; however, this cutoff is highly study/tissue
dependent and may need to be reduced; what is most important is
consistency in the nuclei distribution for segments within the study.
Area: generally correlates with nuclei; a strict cutoff is not generally
applied based on area.

# 4.1.1 Select Segment QC

First, we select the QC parameter cutoffs, against which our ROI/AOI
segments will be tested and flagged appropriately. We have selected the
appropriate study-specific parameters for this study. Note: the default
QC values recommended above are advised when surveying a new dataset for
the first time.

Default QC cutoffs are commented in () adjacent to the respective
parameters study-specific values were selected after visualizing the QC
results in more detail below

```{r set_QC_params}
QC_params <-
  list(minSegmentReads = 1000, # Minimum number of reads (1000)
       percentTrimmed = 80,    # Minimum % of reads trimmed (80%)
       percentStitched = 80,   # Minimum % of reads stitched (80%)
       percentAligned = 75,    # Minimum % of reads aligned (80%)
       percentSaturation = 50, # Minimum sequencing saturation (50%)
       minNegativeCount = 1,   # Minimum negative control counts (10)
       maxNTCCount = 9000,     # Maximum counts observed in NTC well (1000)
       minNuclei = 20,        # Minimum # of nuclei estimated (100)
       minArea = 1000)         # Minimum segment area (5000)
Data <-
  setSegmentQCFlags(Data, qcCutoffs = QC_params)        

cat("pre-QC features:", dim(Data)[1], "\npre-QC samples:", dim(Data)[2])

#Table for clarification
QCparams_df <- data.frame (
  items = c("minSegmentReads","percentTrimmed","percentStitched","percentAligned","percentSaturation",
            "minNegativeCount","maxNTCCount","minNuclei","minArea"),
  defaults = c(1000,80,80,80,50,10,1000,100,5000),
  actual = c(QC_params$minSegmentReads,QC_params$percentTrimmed,QC_params$percentStitched,QC_params$percentAligned,QC_params$percentSaturation,QC_params$minNegativeCount,QC_params$maxNTCCount,QC_params$minNuclei,QC_params$minArea)
)

datatable(QCparams_df, rownames=FALSE,
          caption = "QC thresholds",
          extensions = 'Buttons', options = list (
            dom = 'Bftrip',
            buttons = c('copy', 'csv', 'excel', 'pdf', 'print')
          )
)

```

Collate QC Results

```{r collate_QC_results}
QCResults <- protocolData(Data)[["QCFlags"]]
flag_columns <- colnames(QCResults)
QC_Summary <- data.frame(Pass = colSums(!QCResults[, flag_columns]),
                         Warning = colSums(QCResults[, flag_columns]))

QCResults$QCStatus <- apply(QCResults, 1L, function(x) {
  ifelse(sum(x) == 0L, "PASS", "WARNING")
})

QC_Summary["TOTAL FLAGS", ] <-
  c(sum(QCResults[, "QCStatus"] == "PASS"),
    sum(QCResults[, "QCStatus"] == "WARNING"))

col_by <- "ANN1"
col_by_plate <- "Plate_ID"
```

# 4.2 Graphical summaries of QC statistics {.tabset .tabset-pills}

Use the tab-menu to navigate!

```{r QC_plotting}
QC_histogram <- function(assay_data = NULL,
                         annotation = NULL,
                         fill_by = NULL,
                         thr = NULL,
                         scale_trans = NULL) {
  plt <- ggplot(assay_data,
                aes_string(x = paste0("unlist(`", annotation, "`)"),
                           fill = fill_by)) +
    geom_histogram(bins = 50) +
    geom_vline(xintercept = thr, lty = "dashed", color = "black") +
    theme_bw() + guides(fill = "none") +
    facet_wrap(as.formula(paste("~", fill_by)), nrow = 4) +
    scale_fill_manual(values=color_list$ANN1) +
    labs(x = annotation, y = "segments, #", title = annotation)
  if(!is.null(scale_trans)) {
    plt <- plt +
      scale_x_continuous(trans = scale_trans)
  }
  plt
}
```

## Trimmed

```{r}
QC_histogram(sData(Data), "Trimmed (%)", col_by, QC_params$percentTrimmed)
```

## Stiched (%)

```{r}
QC_histogram(sData(Data), "Stitched (%)", col_by, QC_params$percentStitched)
```

## Aligned (%)

```{r}
QC_histogram(sData(Data), "Aligned (%)", col_by,QC_params$percentAligned)
```

## Sequencing Saturation (%) {.active}

```{r}
QC_histogram(sData(Data), "Saturated (%)", col_by, QC_params$percentSaturation) +
  labs(title = "Sequencing Saturation (%)",
       x = "Sequencing Saturation (%)")
```

## Area

```{r}
QC_histogram(sData(Data), "area", col_by, QC_params$minArea, scale_trans = "log10")
```

## Nuclei count

```{r}
QC_histogram(sData(Data), "nuclei", col_by, QC_params$minNuclei)
```

## DuplicationRate

```{r}
ggplot(pData(protocolData(Data)),
       aes(x = Plate_ID, fill=Plate_ID,
          y = (DeduplicatedReads/Raw))) +
  geom_violin() +
  geom_jitter(width = .2) +
  labs(y = "Deduplicated / Raw reads") +
  scale_y_continuous(labels = scales::percent) +
  theme_bw()

# Plate_ID to check the low dub/raw count
QC_histogram(sData(Data), "Saturated (%)", col_by_plate, QC_params$percentSaturation) +
  labs(title = "Sequencing Saturation (%)",
       x = "Sequencing Saturation (%)")

```

## Negprobes vs Endogenous

```{r plot_negprobe_data, fig.width=10,fig.height=5}
tmp_target_Data <- aggregateCounts(Data)

#get negative probe data
negs<-subset(tmp_target_Data,CodeClass=="Negative")

p1<-ggplot(pData(negs),
       aes(x = ANN1, fill = ANN1,
          y = assayDataElement(negs, elt = "exprs"))) +
  geom_violin() +
  geom_jitter(width = .2) +
  labs(y = "Negative probes Expression") +
  scale_y_continuous(limits = c(1,3000), trans = "log2") +
  theme_bw()


# get endogenous probe data
end<-subset(tmp_target_Data,CodeClass=="Endogenous")

p2<-ggplot(pData(end),
       aes(x = ANN1, fill = ANN1,
           y = colMeans(assayDataElement(end, elt = "exprs")))) +
  geom_violin() +
  geom_jitter(width = .2) +
  labs(y = "Endogenous probes Expression (mean)") +
  scale_y_continuous(limits = c(1,3000),trans = "log2") +
  theme_bw()

pl <-list(p1,p2)
plot_grid(plotlist=pl, nrow=1, align='h')

```

## Neg_probe reads compared to raw_reads

```{r}

# make background total neg probe count
fdata_df<-fData(Data)
negprobesnames<-rownames(fdata_df[fdata_df$Negative==TRUE,])
temp_exp<-assayDataElement(Data,elt='exprs')
negprobe_expr_fd<-temp_exp[rownames(temp_exp) %in% negprobesnames,]
tot_neg_ctrl_reads<-colSums(negprobe_expr_fd)
tot_dedup_reads<-pData(protocolData(Data))$DeduplicatedReads

df<-data.frame('aoi'= names(tot_neg_ctrl_reads),'tot_dedup_reads' = as.numeric(tot_dedup_reads),'tot_neg_ctrl_reads'=as.numeric(tot_neg_ctrl_reads))
df<-melt(df,id="aoi")
ggplot(df,aes(fill=variable,y=value,x=aoi)) + 
  geom_bar(position="identity",stat="identity") +
  scale_y_continuous(trans = log2_trans()) +
  theme(legend.position="bottom",axis.text.x = element_blank(),axis.ticks.x=element_blank())                     
 
```

## Duplicated reads vs Background

```{r}
# get dcc per plate. sum negprobe counts/dcc/plate
ggplot(pData(protocolData(Data)),
       aes(x = Plate_ID, fill=Plate_ID,
          y = DeduplicatedReads)) +
  geom_violin() +
  geom_jitter(width = .2) +
  labs(y = "Deduplicated / Raw reads") +
  scale_y_log10()+
  geom_hline(data =pData(protocolData(Data)) , 
           aes(yintercept = NTC, colour=Plate_ID)) +
  theme_bw()

```

## Duplicated reads vs ROIarea

```{r, fig.width=15,fig.height=5}
temp_df<-cbind(pData(Data),pData(protocolData(Data)),dcc=rownames(pData(Data)))

ggplot(temp_df,
       aes(x = dcc, colour=slide_name,
          y = (DeduplicatedReads/area) )) +
  geom_point() +
  ylim(0,20) + 
  labs(y = "Deduplicated reads / ROI area") +
  theme(axis.text.x = element_text(size =6, angle=90, hjust=1) )

```

## Duplicated reads vs nuclei

```{r, fig.width=15,fig.height=5}
temp_df<-cbind(pData(Data),pData(protocolData(Data)),dcc=rownames(pData(Data)))

ggplot(temp_df,
       aes(x = dcc, colour=slide_name,
          y = (DeduplicatedReads/nuclei) )) +
  geom_point() +
  ylim(0,200) +
  labs(y = "Deduplicated reads / nuclei") +
  theme(axis.text.x = element_text(size =6, angle=90, hjust=1) )

```

# 4.3 Process Negative GeoMeans

```{r}
# Calculate the negative geometric means for each module
# It will show only the negative probes geomean, so expect less segments.
negativeGeoMeans <- 
  esBy(negativeControlSubset(Data), 
       GROUP = "Module", 
       FUN = function(x) { 
         assayDataApply(x, MARGIN = 2, FUN = ngeoMean, elt = "exprs") 
       }) 
protocolData(Data)[["NegGeoMean"]] <- negativeGeoMeans

negCols <- paste0("NegGeoMean_", modules)
pData(Data)[, negCols] <- sData(Data)[["NegGeoMean"]]
for(ann in negCols) {
  plt <- QC_histogram(pData(Data), ann, col_by, 2, scale_trans = "log10")
  print(plt)
}


# Detatch neg_geomean columns ahead of aggregateCounts call

pData(Data) <- pData(Data)[, !colnames(pData(Data)) %in% negCols]

```

Show all NTC values, Freq = \# of Segments with a given NTC count:

```{r QC_tables}
QC<-sData(Data)

ntc_df <-QC[,c("slide_name","Plate_ID","NTC_ID","NTC")]
temptable<-ntc_df %>% dplyr::count(ntc_df$slide_name,ntc_df$NTC_ID,ntc_df$Plate_ID,ntc_df$NTC)
colnames(temptable) <- c("Slide_name","NTC_ID","Plate_ID","NTC_count","Number_of_samples")
datatable(temptable, rownames = FALSE)


kable(table(NTC_Count = sData(Data)$NTC), col.names = c("NTC Count", "# of Segments"))

kable(QC_Summary, caption = "QC Summary Table for each Segment")

datatable(QC_Summary,
          caption = "AOI QC Summary",
          extensions = 'Buttons', options = list (
            dom = 'Bftrip',
            buttons = c('copy', 'csv', 'excel', 'pdf', 'print')
          )
)
```

Show AOIs which fail critical QCs.

```{r list_failures}
QC<-sData(Data)
undersat<-subset(QC, `Saturated (%)`<= QC_params$percentSaturation)

if(nrow(undersat)> 0) {

datatable(aggregate(undersat, by=list(undersat$SampleID),paste,collapse=";"),
          extensions = 'Buttons', options = list (
            dom = 'Bftrip',
            buttons = c('copy', 'csv', 'excel', 'pdf', 'print')
          )
)}
```

Subsetting our dataset has removed samples which did not pass QC

```{r subsetting_QC_fails}
Data <- Data[, QCResults$QCStatus == "PASS"]
```

Generally keep the qcCutoffs parameters unchanged. Set
removeLocalOutliers to FALSE if you do not want to remove local outliers

```{r process_QC}
Data <- setBioProbeQCFlags(Data, 
                               qcCutoffs = list(minProbeRatio = 0.1,
                                                percentFailGrubbs = 20), 
                               removeLocalOutliers = FALSE)

ProbeQCResults <- fData(Data)[["QCFlags"]]
```

Define QC table for Probe QC

```{r define_qc_table}
qc_df <- data.frame(Passed = sum(rowSums(ProbeQCResults[, -1]) == 0),
                    Global = sum(ProbeQCResults$GlobalGrubbsOutlier),
                    Local = sum(rowSums(ProbeQCResults[, -2:-1]) > 0
                                & !ProbeQCResults$GlobalGrubbsOutlier))
```

Subset object to exclude all that did not pass Ratio & Global testing

```{r subset}
ProbeQCPassed <- 
  subset(Data, 
         fData(Data)[["QCFlags"]][,c("LowProbeRatio")] == FALSE &
           fData(Data)[["QCFlags"]][,c("GlobalGrubbsOutlier")] == FALSE)

Data <- ProbeQCPassed 
cat("After QC features:", dim(Data)[1], "\nAfter QC samples:", dim(Data)[2])
```

Check how many unique targets the object has

```{r unique_check}
length(unique(featureData(Data)[["TargetName"]]))
```

Collapse to targets

```{r collaps_targets}
target_Data <- aggregateCounts(Data)

exprs(target_Data)[1:5, 1:2]
```

Define LOQ SD threshold and minimum value

```{r set_LSQ}
cutoff <- 2
minLOQ <- 2
```

# 4.4 Limit of Quantification

We define a limit of quantification (LOQ) per ROI/AOI segment based on
the negative control probes to guide the filtering of segments and genes
with low signal relative to background. The formula for calculating the
LOQ in the $i^{th}$ segment at $n$ standard deviations ($n = 2$ for this
study) is: $LOQ_i=geomean(NegProbe_i)*geoSD(NegProbe_i)^n$

Calculate LOQ per module tested

```{r calculate_LOQ}
LOQ <- data.frame(row.names = colnames(target_Data))
for(module in modules) {
  vars <- paste0(c("NegGeoMean_", "NegGeoSD_"),
                 module)
  if(all(vars[1:2] %in% colnames(pData(target_Data)))) {
    LOQ[, module] <-
      pmax(minLOQ,
           pData(target_Data)[, vars[1]] * 
             pData(target_Data)[, vars[2]] ^ cutoff)
  }
}
pData(target_Data)$LOQ <- LOQ
```

# 4.5 Filtering

After determining the limit of quantification (LOQ) per segment, we
recommend filtering out either segments and/or genes with abnormally low
signal. Filtering is an important step to focus on the true biological
data of interest.

We determine the number of genes detected in each segment across the
dataset.

```{r filtering}
LOQ_Mat <- c()
for(module in modules) {
  ind <- fData(target_Data)$Module == module
  Mat_i <- t(esApply(target_Data[ind, ], MARGIN = 1,
                     FUN = function(x) {
                       x > LOQ[, module]
                     }))
  LOQ_Mat <- rbind(LOQ_Mat, Mat_i)
}
# ensure ordering since this is stored outside of the geomxSet
LOQ_Mat <- LOQ_Mat[fData(target_Data)$TargetName, ]
```

# 4.5.1 Segment Gene Detection

We first filter out segments with exceptionally low signal. These
segments will have a small fraction of panel genes detected above the
LOQ relative to the other segments in the study. Let's visualize the
distribution of segments with respect to their % genes detected:

Save detection rate information to pheno data

```{r save_detectino_rate}
pData(target_Data)$GenesDetected <- 
  colSums(LOQ_Mat, na.rm = TRUE)
pData(target_Data)$GeneDetectionRate <-
  pData(target_Data)$GenesDetected / nrow(target_Data)

```

Determine detection thresholds: 1%, 5%, 10%, 15%, \>15%

```{r determine+thresholds}
pData(target_Data)$DetectionThreshold <- 
  cut(pData(target_Data)$GeneDetectionRate,
      breaks = c(0, 0.01, 0.05, 0.1, 0.15, 0.2,1),
      labels = c("<1%", "1-5%", "5-10%", "10-15%", "15-20%", ">20%"))

# stacked bar plot of different cut points (1%, 5%, 10%, 15%)
ggplot(pData(target_Data),
       aes(x = DetectionThreshold)) +
  geom_bar(aes(fill = ANN1)) +
  geom_text(stat = "count", aes(label = ..count..), vjust = -0.5) +
  theme_bw() +
  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
  scale_fill_manual(values=color_list$ANN1) +
  labs(x = "Gene Detection Rate",
       y = "Segments, #",
       fill = "Segment Type")
```

cut percent genes detected at 1, 5, 10, 15

```{r cut_to_percent}
kable(table(pData(target_Data)$DetectionThreshold,
            pData(target_Data)$ANN1))

# set threshold for detectionlevel
# default 0.1
gene_det_threshold <- 0.05

target_Data <-
  target_Data[, pData(target_Data)$GeneDetectionRate >= gene_det_threshold]

dim(target_Data)
```

# 4.5.2 collect annotations

```{r select_annotations2}

# **Select the annotations we want to show, use `` to surround column names with spaces or special symbols**
old_count_mat<-count_mat
count_mat <- dplyr::count(pData(Data), ANN1,ANN2,ANN3,ANN4,slide_name)

# simplify_slide_names if needed
#count_mat$slide_name <- gsub("disease", "d", gsub("normal", "n", count_mat$slide_name))

# gather the data and plot in order: class, slide name, region, segment
test_gr <- gather_set_data(count_mat, 1:ann_size)
test_gr$x <- 
  factor(test_gr$x, 
         levels = ann_names)


aoilist <-names(as.data.frame(assayDataElement(target_Data, elt= "exprs")))

ANN1 <-as.data.frame(pData(target_Data)$ANN1,unique(count_mat$ANN1))
colnames(ANN1) <- "class"
row.names(ANN1) <-aoilist

ANN2 <-as.data.frame(pData(target_Data)$ANN2,unique(count_mat$ANN2))
colnames(ANN2) <- "slide_ann"
row.names(ANN2) <-aoilist

ANN3 <-as.data.frame(pData(target_Data)$ANN3,unique(count_mat$ANN3))
colnames(ANN3) <- "region"
row.names(ANN3) <-aoilist

ANN4 <-as.data.frame(pData(target_Data)$ANN4,unique(count_mat$ANN4))
colnames(ANN4) <- "path"
row.names(ANN4) <-aoilist

SN <-as.data.frame(pData(target_Data)$slide_name, unique(count_mat$slide_name))
colnames(SN) <- "slide_name"
row.names(SN) <-aoilist

ann<-cbind(ANN1,ANN2,ANN3,ANN4,SN)
```

# 4.6 Manual removal of samples/classes

```{r remove_samples}
active_aois<-rownames(ann)
```

re-Collect annotations

```{r collect_annotations}
# gather the data and plot in order: class, slide name, region, segment
test_gr <- gather_set_data(count_mat, 1:ann_size)
test_gr$x <-
  factor(test_gr$x,
         levels = ann_names)

```

re-Plot Sankey

```{r plot_sankey, fig.width=20,fig.height=11}
ggplot(test_gr, aes(x, id = id, split = y, value = n)) +
  geom_parallel_sets(aes(fill = ANN1), alpha = 0.5, axis.width = 0.1) +
  geom_parallel_sets_axes(axis.width = 0.2) +
  geom_parallel_sets_labels(color = "white", size = 5) +
  theme_classic(base_size = 17) + 
  theme(legend.position = "bottom",
        axis.ticks.y = element_blank(),
        axis.line = element_blank(),
        axis.text.y = element_blank()) +
  scale_y_continuous(expand = expansion(0)) + 
  scale_x_discrete(expand = expansion(0)) +
  scale_fill_manual(values=color_list$ANN1) +
  labs(x = "", y = "") +
  annotate(geom = "segment", x = 3.25, xend = 3.25, y = 10, 
           yend = 60, lwd = 2) +
  annotate(geom = "text", x = 3.19, y = 25, angle = 90, size = 5,
           hjust = 0.5, label = "50 segments")
```

# 4.7 Gene Detection Rate

Calculate detection rate

```{r clc_detection_rate}
LOQ_Mat <- LOQ_Mat[, colnames(target_Data)]
fData(target_Data)$DetectedSegments <- rowSums(LOQ_Mat, na.rm = TRUE)
fData(target_Data)$DetectionRate <-
  fData(target_Data)$DetectedSegments / nrow(pData(target_Data))
```

Gene of interest detection table

```{r gene_of_interest_table}
goi <- c("PDCD1", "CD274", "IFNG", "CD8A", "CD68", "EPCAM",
         "KRT18", "NPHS1", "NPHS2", "CALB1", "CLDN8")
goi_df <- data.frame(
  Gene = goi,
  Number = fData(target_Data)[goi, "DetectedSegments"],
  DetectionRate = percent(fData(target_Data)[goi, "DetectionRate"]))
```

# 4.8 Gene Filtering

We will graph the total number of genes detected in different
percentages of segments. Based on the visualization below, we can better
understand global gene detection in our study and select how many low
detected genes to filter out of the dataset. Gene filtering increases
performance of downstream statistical tests and improves interpretation
of true biological signal.

Plot detection rate

```{r plot_det_rate}
plot_detect <- data.frame(Freq = c(1, 5, 10, 20, 30, 50))
plot_detect$Number <-
  unlist(lapply(c(0.01, 0.05, 0.1, 0.2, 0.3, 0.5),
                function(x) {sum(fData(target_Data)$DetectionRate >= x)}))
plot_detect$Rate <- plot_detect$Number / nrow(fData(target_Data))
rownames(plot_detect) <- plot_detect$Freq

ggplot(plot_detect, aes(x = as.factor(Freq), y = Rate, fill = Rate)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = formatC(Number, format = "d", big.mark = ",")),
            vjust = 1.6, color = "black", size = 4) +
  scale_fill_gradient2(low = "orange2", mid = "lightblue",
                       high = "dodgerblue3", midpoint = 0.65,
                       limits = c(0,1),
                       labels = scales::percent) +
  theme_bw() +
  scale_y_continuous(labels = scales::percent, limits = c(0,1),
                     expand = expansion(mult = c(0, 0))) +
  labs(x = "% of Segments",
       y = "Genes Detected, % of Panel > LOQ")
```

Subset to target genes detected in at least 10% of the samples. Also
manually include the negative control probe, for downstream use

```{r subset_to_10p_detected_genes}
# default=0.1
negativeProbefData <- subset(fData(target_Data), CodeClass == "Negative")
neg_probes <- unique(negativeProbefData$TargetName)
target_Data <- 
  target_Data[fData(target_Data)$DetectionRate >= 0.05 |
                    fData(target_Data)$TargetName %in% neg_probes, ]

# retain only detected genes of interest
goi <- goi[goi %in% rownames(target_Data)]
```

# 5 Normalization

We will now normalize the GeoMx data for downstream visualizations and
differential expression. The two common methods for normalization of
DSP-NGS RNA data are i) quartile 3 (Q3) or ii) background normalization.

Both of these normalization methods estimate a normalization factor per
segment to bring the segment data distributions together. More advanced
methods for normalization and modeling are under active development.
However, for most studies, these methods are sufficient for
understanding differences between biological classes of segments and
samples.

Q3 normalization is typically the preferred normalization strategy for
most DSP-NGS RNA studies. Given the low negative probe counts in this
particular dataset as shown during Segment QC, we would further avoid
background normalization as it may be less stable.

Before normalization, we will explore the relationship between the upper
quartile (Q3) of the counts in each segment with the geometric mean of
the negative control probes in the data. Ideally, there should be a
separation between these two values to ensure we have stable measure of
Q3 signal. If you do not see sufficient separation between these values,
you may consider more aggressive filtering of low signal segments/genes.

Graph Q3 value vs negGeoMean of Negatives

```{r lpot_q3_negGeoMean}
ann_of_interest <- "ANN3"
Stat_data <- 
  data.frame(row.names = colnames(exprs(target_Data)),
             Segment = colnames(exprs(target_Data)),
             Annotation = pData(target_Data)[, ann_of_interest],
             Q3 = unlist(apply(exprs(target_Data), 2,
                               quantile, 0.75, na.rm = TRUE)),
             NegProbe = exprs(target_Data)[neg_probes, ])
Stat_data_m <- melt(Stat_data, measure.vars = c("Q3", "NegProbe"),
                    variable.name = "Statistic", value.name = "Value")

plt1 <- ggplot(Stat_data_m,
               aes(x = Value, fill = Statistic)) +
  geom_histogram(bins = 40) + theme_bw() +
  scale_x_continuous(trans = "log2") +
  facet_wrap(~Annotation, nrow = 1) + 
  scale_fill_brewer(palette = 3, type = "qual") +
  labs(x = "Counts", y = "Segments, #")

plt2 <- ggplot(Stat_data,
               aes(x = NegProbe, y = Q3, color = Annotation)) +
  geom_abline(intercept = 0, slope = 1, lty = "dashed", color = "darkgray") +
  geom_point() + guides(color = "none") + theme_bw() +
  scale_x_continuous(trans = "log2") + 
  scale_y_continuous(trans = "log2") +
  theme(aspect.ratio = 1) +
  labs(x = "Negative Probe GeoMean, Counts", y = "Q3 Value, Counts")

plt3 <- ggplot(Stat_data,
               aes(x = NegProbe, y = Q3 / NegProbe, color = Annotation)) +
  geom_hline(yintercept = 1, lty = "dashed", color = "darkgray") +
  geom_point() + theme_bw() +
  scale_x_continuous(trans = "log2") + 
  scale_y_continuous(trans = "log2") +
  theme(aspect.ratio = 1) +
  labs(x = "Negative Probe GeoMean, Counts", y = "Q3/NegProbe Value, Counts")

btm_row <- plot_grid(plt2, plt3, nrow = 1, labels = c("B", ""),
                     rel_widths = c(0.43,0.57))
plot_grid(plt1, btm_row, ncol = 1, labels = c("A", ""))

```

Q3 norm (75th percentile) for WTA/CTA with or without custom spike-ins

```{r q3_norm}
target_Data <- normalize(target_Data ,
                             norm_method = "quant", 
                             desiredQuantile = .75,
                             toElt = "q_norm")
#, data_type = "RNA" depricated after 4.1

```

Background normalization for WTA/CTA without custom spike-in

```{r bg_norm}
target_Data <- normalize(target_Data,
                             norm_method = "neg", 
                             fromElt = "exprs",
                             toElt = "neg_norm")

# , data_type = "RNA" depricated after 4.1
```

# 5.1 Visualize the first 10 segments with each normalization method {.tabset .tabset-pills}

Use the tab-menu to navigate!

```{r visulaize_norms}

#Fix zero values, which go to -inf in log transform in standard boxplot
# temp <-as.matrix(exprs((target_Data)[,1:10]))
# long <- melt(temp)
# colnames(long) <- c("gene","segment","count")
# ggplot(long, aes(x=segment,y=count)) +
#     geom_boxplot(fill="#9EDAE5") +
#     scale_y_continuous(trans=scales::pseudo_log_trans(base = 10)) +
#     scale_x_discrete(labels=c(1:10)) +
#     labs(title="Raw counts", x="segment", y = "Counts, Raw")
# 
# 
# temp <-as.matrix(assayDataElement(target_Data[,1:10], elt = "q_norm"))
# long <- melt(temp)
# colnames(long) <- c("gene","segment","count")
# ggplot(long, aes(x=segment,y=count)) +
#     geom_boxplot(fill = "#2CA02C") +
#     scale_y_continuous(trans=scales::pseudo_log_trans(base = 10)) +
#     scale_x_discrete(labels=c(1:10)) +
#     labs(title="Q3 Norm Counts", x="segment", y = "Counts, Q3 Normalized")
# 
# 
# temp <-as.matrix(assayDataElement(target_Data[,1:10], elt = "neg_norm"))
# long <- melt(temp)
# colnames(long) <- c("gene","segment","count")
# ggplot(long, aes(x=segment,y=count)) +
#     geom_boxplot(fill = "#FF7F0E") +
#     scale_y_continuous(trans=scales::pseudo_log_trans(base = 10)) +
#     scale_x_discrete(labels=c(1:10)) +
#     labs(title="Neg Norm Counts", x="segment", y = "Counts, Neg. Normalized")
```

## raw counts

```{r}
boxplot(exprs(target_Data)[,1:8],
        col = "#9EDAE5", main = "Raw Counts",
        log = "y", names = 1:8, xlab = "Segment",
        ylab = "Counts, Raw")
```

## Q3 normalized {.active}

```{r}
boxplot(assayDataElement(target_Data[,1:8], elt = "q_norm"),
        col = "#2CA02C", main = "Q3 Norm Counts",
        log = "y", names = 1:8, xlab = "Segment",
        ylab = "Counts, Q3 Normalized")
```

## Negative probe normalization

```{r}
boxplot(assayDataElement(target_Data[,1:8], elt = "neg_norm"),
        col = "#FF7F0E", main = "Neg Norm Counts",
        log = "y", names = 1:8, xlab = "Segment",
        ylab = "Counts, Neg. Normalized")

```

# 6 Unsupervised Analysis

# 6.1 UMAP {.tabset .tabset-pills}

Use the tab-menu to navigate!

## 1

```{r umap, fig.width=10,fig.height=8}
gc()
custom_umap <- umap::umap.defaults
custom_umap$random_state <- 42
# run UMAP

umap_out <-
  umap(t(log2(assayDataElement(target_Data , elt = "q_norm"))),
       config = custom_umap)
pData(target_Data)[, c("UMAP1", "UMAP2")] <- umap_out$layout[, c(1,2)]
ggplot(pData(target_Data),
       aes(x = UMAP1, y = UMAP2, color = ANN1, shape = slide_name)) +

  geom_point(size = 3) +
  #geom_text_repel(aes(label=row.names(pData(target_Data))), size=2,max.overlaps = 100)+
  theme_bw()
```

## 2

```{r, fig.width=10,fig.height=8}
umap_out <-
  umap(t(log2(assayDataElement(target_Data , elt = "q_norm"))),
       config = custom_umap)
pData(target_Data)[, c("UMAP1", "UMAP2")] <- umap_out$layout[, c(1,2)]
ggplot(pData(target_Data),
       aes(x = UMAP1, y = UMAP2, color = ANN2, shape = ANN1)) +
  geom_point(size = 3) +
  #geom_text_repel(aes(label=row.names(pData(target_Data))), size=2,max.overlaps = 100)+
  theme_bw()
```

## 3

```{r, fig.width=10,fig.height=8}
umap_out <-
  umap(t(log2(assayDataElement(target_Data , elt = "q_norm"))),
       config = custom_umap)
pData(target_Data)[, c("UMAP1", "UMAP2")] <- umap_out$layout[, c(1,2)]
ggplot(pData(target_Data),
       aes(x = UMAP1, y = UMAP2, color = ANN3, shape = ANN2)) +
  geom_point(size = 3) +
  #geom_text_repel(aes(label=row.names(pData(target_Data))), size=2,max.overlaps = 100)+
  theme_bw()
```

# 6.1 Run tSNE {.tabset .tabset-pills}

Use the tab-menu to navigate!

One common approach to understanding high-plex data is dimension
reduction. Two common methods are UMAP and tSNE, which are
non-orthogonally constrained projections that cluster samples based on
overall gene expression. In this study, we see by either UMAP (from the
umap package) or tSNE (from the Rtsne package)

## 1

```{r tSNE, fig.width=10,fig.height=8}
set.seed(42) # set the seed for tSNE as well

tsne_out <-
  Rtsne(t(log2(assayDataElement(target_Data , elt = "q_norm"))),
        perplexity = ncol(target_Data)*.15)
pData(target_Data)[, c("tSNE1", "tSNE2")] <- tsne_out$Y[, c(1,2)]
ggplot(pData(target_Data),
       aes(x = tSNE1, y = tSNE2, shape = ANN3, color = ANN1)) +
  geom_point(size = 3) +
  geom_text_repel(aes(label=row.names(pData(target_Data))), size=2,max.overlaps = 100)+
  theme_bw()
```

## 2

```{r, fig.width=10,fig.height=8}
tsne_out <-
  Rtsne(t(log2(assayDataElement(target_Data , elt = "q_norm"))),
        perplexity = ncol(target_Data)*.15)
pData(target_Data)[, c("tSNE1", "tSNE2")] <- tsne_out$Y[, c(1,2)]
ggplot(pData(target_Data),
       aes(x = tSNE1, y = tSNE2, color = ANN2, shape = ANN1)) +
  geom_point(size = 3) +
  #geom_text_repel(aes(label=row.names(pData(target_Data))), size=2,max.overlaps = 100)+
  theme_bw()
```

## 3

```{r, fig.width=10,fig.height=8}
tsne_out <-
  Rtsne(t(log2(assayDataElement(target_Data , elt = "q_norm"))),
        perplexity = ncol(target_Data)*.15)
pData(target_Data)[, c("tSNE1", "tSNE2")] <- tsne_out$Y[, c(1,2)]
ggplot(pData(target_Data),
       aes(x = tSNE1, y = tSNE2, color = ANN3, shape = ANN2)) +
  geom_point(size = 3) +
  #geom_text_repel(aes(label=row.names(pData(target_Data))), size=2,max.overlaps = 100)+
  theme_bw()
```

# 6.2 Clustering high CV Genes {.tabset .tabset-pills}

Another approach to explore the data is to calculate the coefficient of
variation ($CV$) for each gene ($g$) using the formula
$CV_g=SD_g/mean_g$. We then identify genes with high CVs that should
have large differences across the various profiled segments. This
unbiased approach can reveal highly variable genes across the study.

We plot the results using unsupervised hierarchical clustering,
displayed as a heatmap.

```{r clustering1}
# create a log2 transform of the data for analysis
assayDataElement(object = target_Data, elt = "log_q") <-
  assayDataApply(target_Data, 2, FUN = log, base = 2, elt = "q_norm")

# create CV function
calc_CV <- function(x) {sd(x) / mean(x)}
CV_dat <- assayDataApply(target_Data,
                         elt = "log_q", MARGIN = 1, calc_CV)
# show the highest CD genes and their CV values
sort(CV_dat, decreasing = TRUE)[1:5]
```

## Table of CV values

```{r}
# show the highest CD genes and their CV values
datatable(as.data.frame(CV_dat),
          extensions = 'Buttons', options = list (
            order = list(1, 'desc'),
            dom = 'Bftrip',
            buttons = c('copy', 'csv', 'excel', 'pdf', 'print')
          ), caption = "CV values of genes" 
) %>% formatRound(columns=c("CV_dat"), digits=3)

```

## Heatmap genes in the top 3rd of the CV values {.active}

```{r CVheatmap, fig.width=20,fig.height=15}
GOI <- names(CV_dat)[CV_dat > quantile(CV_dat, 0.75)]

pheatmap(assayDataElement(target_Data[GOI, ], elt = "log_q"),
         scale = "row",
         cutree_cols = 3,
         cutree_rows = 3,
         show_rownames = FALSE, show_colnames = TRUE,
         border_color = NA,
         drop_levels = TRUE,
         clustering_method = "average",
         clustering_distance_rows = "correlation",
         clustering_distance_cols = "correlation",
         breaks = seq(-3, 3, 0.05),
         color = colorRampPalette(c("purple3", "black", "yellow2"))(120),
         annotation_colors = color_list,
         annotation_col = pData(target_Data)[, ann_names])

```

```{r log_transform}
assayDataElement(object = target_Data, elt = "log_q") <-  assayDataApply(target_Data, 2, FUN = log, base = 2, elt = "q_norm")
log_q <-as.data.frame(assayDataElement(target_Data, elt= "log_q"))
```

# 6.2.0 Create subset of data

```{r define_active_aois}
# determine AOIs to use
#active_aois<-rownames(ann)[ann$patient=="p4"]
active_aois<-rownames(ann)

```

# 6.2.1 Clustering high CV genes for subset {.tabset .tabset-pills}

Calculating CV values

```{r clustering_subset, fig.width=10,fig.height=15}
# create a log2 transform of the data for analysis
assayDataElement(object = target_Data, elt = "log_q") <-
  assayDataApply(target_Data, 2, FUN = log, base = 2, elt = "q_norm")

# create CV function
calc_CV <- function(x) {sd(x) / mean(x)}
CV_dat <- assayDataApply(target_Data[,active_aois],
                         elt = "log_q", MARGIN = 1, calc_CV)

```

## Table of CV values

```{r}
# show the highest CD genes and their CV values
datatable(as.data.frame(CV_dat),
          extensions = 'Buttons', options = list (
            order = list(1, 'desc'),
            dom = 'Bftrip',
            buttons = c('copy', 'csv', 'excel', 'pdf', 'print')
          ), caption = "CV values of genes" 
) %>% formatRound(columns=c("CV_dat"), digits=3)

```

## Heatmap on of subset, genes in the top 3rd of the CV values {.active}

```{r, fig.width=20,fig.height=15}
# Identify genes in the top 3rd of the CV values
GOI <- names(CV_dat)[CV_dat > quantile(CV_dat, 0.75)]
pheatmap(assayDataElement(target_Data[GOI,active_aois ], elt = "log_q"),
        scale = "row",
        fontsize_row = 5,
        cutree_cols = 3,
        cutree_rows = 3,
        show_rownames = FALSE, show_colnames = TRUE,
        border_color = NA,
        clustering_method = "average",
        clustering_distance_rows = "correlation",
        clustering_distance_cols = "correlation",
        breaks = seq(-3, 3, 0.05),
        color = colorRampPalette(c("purple3", "black", "yellow2"))(120),
       annotation_colors = color_list,
        annotation_col =
          pData(target_Data)[, ann_names])
```

# 7.1 Differential Expression

## t-test

```{r, fig.width=20,fig.height=10 }
gc()
plots<-list()
tables<-list()
labels<-list()
test<-"ttest"
mtc<-"BY"
#options: "holm"       "hochberg"   "hommel"     "bonferroni" "BH"         "BY"         "fdr" 
counter=1

comps_df<-data.frame(comp='',val='')
for (class in c("DKD","normal")) {
for (active_group1 in unique(ann$region)) {
    for (active_group2 in unique(ann$region)) {
     
      #supress reduncant compares
      if(active_group1==active_group2) {next}
      comp<-paste(sort(c(class, active_group1,active_group2)),collapse = "_")
      if(comp %in% comps_df$comp) {next}
      temp_df<-data.frame(comp=comp ,val=1)
      comps_df<-rbind(comps_df,temp_df)
      
      labels[[counter]]<-paste(active_group1," vs ", active_group2)
      group1<-log_q[,rownames(ann)[ann$class == class & ann$region==active_group1]]
      group2<-log_q[,rownames(ann)[ann$class == class & ann$region==active_group2]]
      
      #run t_tests  
      results<-as.data.frame ( apply(log_q, 1, function(x) t.test(x[colnames(group1)],x[colnames(group2)])$p.value) )
      colnames(results)<-"raw_p_value"
      
      #multiple_testing_correction
      adj_p_value<- p.adjust(results$raw_p_value,method=mtc)
      results<-cbind(results,adj_p_value)
      
      #calc_fdr
      FDR<- p.adjust(results$raw_p_value,method="fdr")
      results<-cbind(results,FDR)
      
      #fold_changes
      #as base data is already log transformed, means need to be subtracted to get FC in log space
      fchanges<-as.data.frame(apply(log_q, 1, function(x) (mean(x[colnames(group1)]) - mean(x[colnames(group2)]))))
      colnames(fchanges)<-"FC"
      #paste("FC",active_group1," / ",active_group2)
      results<-cbind(results,fchanges)
      
      #add genenames
      results$Gene<-rownames(results)
      
      #set categories based on P-value & FDR for plotting
      results$Color <- "NS or FC < 0.5"
      results$Color[results$adj_p_value < 0.05] <- "P < 0.05"
      results$Color[results$FDR < 0.05] <- "FDR < 0.05"
      results$Color[results$FDR < 0.001] <- "FDR < 0.001"
      results$Color[abs(results$FC) < 1] <- "NS or FC < 1"
      results$Color <- factor(results$Color,
                              levels = c("NS or FC < 1", "P < 0.05", "FDR < 0.05", "FDR < 0.001"))
      
      #vulcanoplot
      
      # pick top genes for either side of volcano to label
      # order genes for convenience:
      
      results$invert_P <- (-log10(results$adj_p_value)) * sign(results$FC)
      top_g <- c()
      top_g <- c(top_g,
                 results[ind, 'Gene'][
                   order(results[ind, 'invert_P'], decreasing = TRUE)[1:15]],
                 results[ind, 'Gene'][order(results[ind, 'invert_P'], decreasing = FALSE)[1:15]])
      top_g<- unique(top_g)
      results <- results[, -1*ncol(results)] # remove invert_P from matrix
      
      # Graph results
      plots[[counter]]<- ggplot(results,
                                      aes(x = FC, y = -log10(adj_p_value),
                                          color = Color, label = Gene)) +
        geom_vline(xintercept = c(1, -1), lty = "dashed") +
        geom_hline(yintercept = -log10(0.05), lty = "dashed") +
        geom_point() +
        labs(x = paste("Enriched in", active_group2," <- log2(FC) -> Enriched in", active_group1),
             y = "Significance, -log10(P)",
             color = "Significance") +
        scale_color_manual(values = c(`FDR < 0.001` = "dodgerblue",
                                      `FDR < 0.05` = "lightblue",
                                      `P < 0.05` = "orange2",
                                      `NS or FC < 0.5` = "gray"),
                           guide = guide_legend(override.aes = list(size = 4))) +
        scale_y_continuous(expand = expansion(mult = c(0,0.05))) +
        geom_text_repel(data = subset(results, FDR<0.001 & (-1>FC| FC>1)),
                        point.padding = 0.15, color = "black", size=3.5,
                        min.segment.length = .1, box.padding = .2, lwd = 2,
                        max.overlaps = 50) +
        theme_bw(base_size = 20) +
        theme(legend.position = "bottom") +
        ggtitle(paste("class: ", class," - ",test, mtc,"multitest corr"))
      
      #store tables for display later
      tables[[counter]]<-results
      
       counter = counter+1
      #datatable(subset(results, Gene %in% GOI), rownames=FALSE,caption = paste("DE results ", active_group1," vs ", active_group2))
    }
  }
}
grid.arrange(grobs=plots,ncol=2)
```

```{r dump_tables,results='asis'}
#strangly does not appear in html output??
for (c in (2:counter-1)) {
  #Gene %in% GOI
  
  print(datatable( subset(tables[[c]], Color == "FDR < 0.001" ), 
           rownames=FALSE,
           extensions = 'Buttons', options = list (
              dom = 'Bftrip',
              buttons = c('copy', 'csv', 'excel', 'pdf', 'print')
            ),
           caption = paste("DE results ", labels[[1]]),filter='top') %>% formatRound(columns=c("raw_p_value","adj_p_value","FDR","FC"), digits=3))
  cat('\n\n<!-- -->\n\n')
}            

```

# 7.2 DE analysis with LMM

A common statistical approach is to use a linear mixed-effect model
(LMM). The LMM allows the user to account for the subsampling per
tissue; in other words, we adjust for the fact that the multiple regions
of interest placed per tissue section are not independent observations,
as is the assumption with other traditional statistical tests. The
formulation of the LMM model depends on the scientific question being
asked.

Overall, there are two flavors of the LMM model when used with GeoMx
data: i) with and ii) without random slope.

When comparing features that co-exist in a given tissue section, a
random slope is included in the LMM model. When comparing features that
are mutually exclusive in a given tissue section the LMM model does not
require a random slope.

Mostly, we use patient/sample as Random Intercept when they are combined
on slides.

![](C:/Users/pkloosterman/Documents/general_workflow/LMM_setup.png)

## glomerulus - tubule

```{r LMM region}
# convert test variables to factors

pData(target_Data)$testRegion <- 
    factor(pData(target_Data)$region, c("glomerulus", "tubule"))

pData(target_Data)[["slide"]]<-factor(pData(target_Data)[["slide_name"]])
assayDataElement(object = target_Data, elt = "log_q") <-  assayDataApply(target_Data, 2, FUN = log, base = 2, elt = "q_norm")

lmm_results <- c()
mixedOutmc <-
    mixedModelDE(target_Data,
                 elt = "log_q",
                 modelFormula = ~ testRegion + (1 + testRegion | slide),
                 groupVar = "testRegion",
                 nCores = parallel::detectCores(),
                 multiCore = FALSE)

# format results as data.frame
 r_test <- do.call(rbind, mixedOutmc["lsmeans", ])
 tests <- rownames(r_test)
 r_test <- as.data.frame(r_test)
 r_test$Contrast <- tests
 
# use lapply in case you have multiple levels of your test factor to
# correctly associate gene name with it's row in the results table
 r_test$Gene <- 
     unlist(lapply(colnames(mixedOutmc),
                   rep, nrow(mixedOutmc["lsmeans", ][[1]])))

 r_test$FDR <- p.adjust(r_test$`Pr(>|t|)`, method = "fdr")
 r_test <- r_test[, c("Gene", "Contrast", "Estimate", "Pr(>|t|)", "FDR")]
 lmm_results <- rbind(lmm_results, r_test)

```

```{r table_of_LMM_results region}
#subset(lmm_results, Gene %in% GOI)
datatable(lmm_results, rownames = FALSE,
          extensions = 'Buttons', options = list (
              dom = 'Bftrip',
              buttons = c('copy', 'csv', 'excel', 'pdf', 'print')
            ),
          caption = "DE results for Genes of Interest (>75% CV)",filter='top') %>% formatRound(columns=c("Estimate","Pr(>|t|)","FDR"), digits=3)
```

## DKD - normal

```{r LMM class}
# convert test variables to factors

pData(target_Data)$testClass <- 
    factor(pData(target_Data)$class, c("DKD", "normal"))

pData(target_Data)[["slide"]]<-factor(pData(target_Data)[["slide_name"]])
assayDataElement(object = target_Data, elt = "log_q") <- assayDataApply(target_Data, 2, FUN = log, base = 2, elt = "q_norm")

lmm_results_d <- c()
mixedOutmc <-
    mixedModelDE(target_Data,
                 elt = "log_q",
                 modelFormula = ~ testClass + (1 | slide),
                 groupVar = "testClass",
                 nCores = parallel::detectCores(),
                 multiCore = FALSE)

# format results as data.frame
 r_test <- do.call(rbind, mixedOutmc["lsmeans", ])
 tests <- rownames(r_test)
 r_test <- as.data.frame(r_test)
 r_test$Contrast <- tests
 
# use lapply in case you have multiple levels of your test factor to
# correctly associate gene name with it's row in the results table
 r_test$Gene <- 
     unlist(lapply(colnames(mixedOutmc),
                   rep, nrow(mixedOutmc["lsmeans", ][[1]])))

 r_test$FDR <- p.adjust(r_test$`Pr(>|t|)`, method = "fdr")
 r_test <- r_test[, c("Gene", "Contrast", "Estimate", "Pr(>|t|)", "FDR")]
 lmm_results_d <- rbind(lmm_results_d, r_test)

```

```{r table_of_LMM_results class}
#subset(lmm_results, Gene %in% GOI)
datatable(lmm_results_d, rownames = FALSE,
          extensions = 'Buttons', options = list (
              dom = 'Bftrip',
              buttons = c('copy', 'csv', 'excel', 'pdf', 'print')
            ),
          caption = "DE results for Genes of Interest (>75% CV)",filter='top') %>% formatRound(columns=c("Estimate","Pr(>|t|)","FDR"), digits=3)
```

# 7.3 Vulcanoplot of LMM

## glomerulus - tubule

```{r lmm_vulcano region, fig.width=10,fig.height=10}
# Categorize Results based on P-value & FDR for plotting
fc_threshold = 0.5

lmm_results$Color <- paste("NS or FC < ",fc_threshold)
lmm_results$Color[lmm_results$`Pr(>|t|)` < 0.05] <- "P < 0.05"
lmm_results$Color[lmm_results$FDR < 0.05] <- "FDR < 0.05"
lmm_results$Color[lmm_results$FDR < 0.001] <- "FDR < 0.001"
lmm_results$Color[abs(lmm_results$Estimate) < fc_threshold] <- "NS or FC < 1"
lmm_results$Color <- factor(lmm_results$Color,
                        levels = c("NS or FC < 1", "P < 0.05",
                                   "FDR < 0.05", "FDR < 0.001"))




# pick top genes for either side of volcano to label
# order genes for convenience:
lmm_results$invert_P <- (-log10(lmm_results$`Pr(>|t|)`)) * sign(lmm_results$Estimate)
top_g <- c()

#loop here over tested conditions if applicable
#for(location in c("BOTTOM","TOP")) {
top_g <- c(top_g,
           lmm_results[, 'Gene'][
             order(lmm_results[, 'invert_P'], decreasing = TRUE)[1:30]],
           lmm_results[, 'Gene'][
             order(lmm_results[, 'invert_P'], decreasing = FALSE)[1:30]])

top_g <- unique(top_g)
lmm_results <- lmm_results[, -1*ncol(lmm_results)] # remove invert_P from matrix


# get significant genes with FDR < 0.001 and fold change > 0.5
#lmm_results_slice <- lmm_results_slice[lmm_results_slice$FDR < 0.001,]
#lmm_results_slice <- lmm_results_slice[lmm_results_slice$Estimate < -0.5 | lmm_results_slice$Estimate > 0.5,]


# Graph results
print(ggplot(lmm_results,
             aes(x = Estimate, y = -log10(`Pr(>|t|)`),
                 color = Color, label = Gene)) +
        geom_vline(xintercept = c(fc_threshold, -fc_threshold), lty = "dashed") +
        geom_hline(yintercept = -log10(0.05), lty = "dashed") +
        geom_point() +
        labs(x = paste(lmm_results$Contrast, " log2(FC)"),
             y = "Significance, -log10(P)",
             color = "Significance") +
        scale_color_manual(values = c(`FDR < 0.001` = "dodgerblue",
                                      `FDR < 0.05` = "lightblue",
                                      `P < 0.05` = "orange2",
                                      `NS or FC < 1` = "gray"),
                           guide = guide_legend(override.aes = list(size = 4))) +
        scale_y_continuous(expand = expansion(mult = c(0,0.05))) +
        geom_text_repel(data = subset(lmm_results, FDR < 0.001 & abs(lmm_results$Estimate) > fc_threshold),
                        point.padding = 0.15, color = "black",size=5,
                        min.segment.length = .1, box.padding = .2, lwd = 2,
                        max.overlaps = 50) +
        theme_bw(base_size = 16) +
        theme(legend.position = "bottom"))
        #+facet_wrap(~Subset, scales = "free_y"))

```

## DKD - normal

```{r lmm_vulcano class, fig.width=10,fig.height=10}
# Categorize Results based on P-value & FDR for plotting
fc_threshold = 0.5

lmm_results_d$Color <- paste("NS or FC < ",fc_threshold)
lmm_results_d$Color[lmm_results_d$`Pr(>|t|)` < 0.05] <- "P < 0.05"
lmm_results_d$Color[lmm_results_d$FDR < 0.05] <- "FDR < 0.05"
lmm_results_d$Color[lmm_results_d$FDR < 0.001] <- "FDR < 0.001"
lmm_results_d$Color[abs(lmm_results_d$Estimate) < fc_threshold] <- "NS or FC < 1"
lmm_results_d$Color <- factor(lmm_results_d$Color,
                        levels = c("NS or FC < 1", "P < 0.05",
                                   "FDR < 0.05", "FDR < 0.001"))




# pick top genes for either side of volcano to label
# order genes for convenience:
lmm_results_d$invert_P <- (-log10(lmm_results_d$`Pr(>|t|)`)) * sign(lmm_results_d$Estimate)
top_g <- c()

#loop here over tested conditions if applicable
#for(location in c("BOTTOM","TOP")) {
top_g <- c(top_g,
           lmm_results_d[, 'Gene'][
             order(lmm_results_d[, 'invert_P'], decreasing = TRUE)[1:30]],
           lmm_results_d[, 'Gene'][
             order(lmm_results_d[, 'invert_P'], decreasing = FALSE)[1:30]])

top_g <- unique(top_g)
lmm_results_d <- lmm_results_d[, -1*ncol(lmm_results_d)] # remove invert_P from matrix


# get significant genes with FDR < 0.001 and fold change > 0.5
#lmm_results_slice <- lmm_results_slice[lmm_results_slice$FDR < 0.001,]
#lmm_results_slice <- lmm_results_slice[lmm_results_slice$Estimate < -0.5 | lmm_results_slice$Estimate > 0.5,]

# Graph results
print(ggplot(lmm_results_d,
             aes(x = Estimate, y = -log10(`Pr(>|t|)`),
                 color = Color, label = Gene)) +
        geom_vline(xintercept = c(fc_threshold, -fc_threshold), lty = "dashed") +
        geom_hline(yintercept = -log10(0.05), lty = "dashed") +
        geom_point() +
        labs(x = paste(lmm_results_d$Contrast, " log2(FC)"),
             y = "Significance, -log10(P)",
             color = "Significance") +
        scale_color_manual(values = c(`FDR < 0.001` = "dodgerblue",
                                      `FDR < 0.05` = "lightblue",
                                      `P < 0.05` = "orange2",
                                      `NS or FC < 1` = "gray"),
                           guide = guide_legend(override.aes = list(size = 4))) +
        scale_y_continuous(expand = expansion(mult = c(0,0.05))) +
        geom_text_repel(data = subset(lmm_results_d,  FDR < 0.001 & abs(lmm_results_d$Estimate) > fc_threshold),
                        point.padding = 0.15, color = "black",size=5,
                        min.segment.length = .1, box.padding = .2, lwd = 2,
                        max.overlaps = 50) +
        theme_bw(base_size = 16) +
        theme(legend.position = "bottom"))
        #+facet_wrap(~Subset, scales = "free_y"))

```

# 7.4 Plotting Genes of Interest

```{r plot_gene_of_interest, fig.width=10,fig.height=5}
my_gois <-unique(subset(lmm_results, `FDR` < 0.001)$Gene)
tmp_tbl<-subset(lmm_results, Gene %in% my_gois)

if(nrow(tmp_tbl) > 1) { 
  datatable(tmp_tbl,rownames = FALSE,caption = "DE results for Genes of Interest ",filter='top') %>% formatRound(columns=c("Estimate","Pr(>|t|)","FDR"), digits=3)
 
for (my_goi in my_gois) {
# show expression for a single target
  a<-ggplot(pData(target_Data),
       aes(x = ANN1, fill = ANN1,
           y = assayDataElement(target_Data[my_goi, ], elt = "q_norm"))) +
  geom_violin() +
  geom_jitter(width = .2) +
  labs(y = paste(my_goi,"Expression")) +
  scale_y_continuous(trans = "log2") +
  facet_wrap(~ANN3, nrow=1) + theme_bw(base_size = 16) +
  theme_bw()
  a
}
}else{
  print("No significant lMM results to plot")
}
```

# 7.5 Heatmap of Significant Genes

In addition to generating individual gene box plots or volcano plots, we
can again create a heatmap from our data. This time rather than
utilizing CV to select genes, we can use the P-value or FDR values to
select genes. Here, we plot all genes with an FDR \< 0.001.

```{r heatmap_sig_genes, fig.width=20,fig.height=20}
my_gois <-unique(subset(lmm_results, `FDR` < 0.001)$Gene)

if(length(my_gois)==0) {
  print("No significant results to show")
 
}else{

pheatmap(log2(assayDataElement(target_Data[my_gois, ], elt = "q_norm")),
         scale = "row",
         show_rownames = TRUE, show_colnames = TRUE,
         border_color = NA,
         clustering_method = "average",
         clustering_distance_rows = "correlation",
         clustering_distance_cols = "correlation",
         cutree_cols = 3, cutree_rows = 2,
         breaks = seq(-3, 3, 0.05),
         color = colorRampPalette(c("purple3", "black", "yellow2"))(120),
         annotation_colors = color_list,
         annotation_col = pData(target_Data)[, ann_names])
}
```

# 8 Pathway Analysis

Pathway analysis enables exploration of different aggregate gene sets
for our experimental questions. Each individual ROI/AOI segment is
scored for every pathway of interest, which we can then use to
investigate biological differences. We will perform analogous analyses
as those outlined in the Differential Expression and Spatial
Deconvolution sections of the report for gene set enrichment.

# 8.1 Scoring Gene Sets

Pathways and gene sets were defined from the Kegg Brite database. We use
an R software package called Gene Set Variation Analysis to score each
segment within our study. see
<https://cran.r-project.org/web/packages/msigdbr/vignettes/msigdbr-intro.html>
for options on collections. We use the KEGG and REACTOME.

```{r build_genesets}
h_gene_sets = rbind(msigdbr(species = "human", subcategory = "CP:KEGG"),
                    msigdbr(species = "human", subcategory = "CP:REACTOME"))
#msigdbr(species = "human", subcategory = "CP:BIOCARTA")

msigdbr_list = split(x = h_gene_sets$gene_symbol, f = h_gene_sets$gs_name)

# prepare df for accurate merging back genes later
pw_gene_df<-data.frame(Pathway = names(msigdbr_list))
pw_gene_df$genes<-msigdbr_list
```

```{r run_gsva}
ssgsea_results <- GSVA::gsva(expr = assayDataElement(target_Data,
                            elt = "log_q"),
                            gset.idx.list = msigdbr_list,
                            method = "zscore",
                            min.sz = 5,
                            max.sz = 500,
                            verbose = FALSE)
geneSetObj <-
  NanoStringGeoMxSet(assayData = ssgsea_results,
                     phenoData = AnnotatedDataFrame(pData(target_Data)),
                     protocolData = protocolData(target_Data),
                     featureType = "GeneSet",
                     check = FALSE)
```

# 8.2 Differental analysis of pathways

## glomerulus - tubule

```{r LMM_of_pathway_analisis region}
# # convert test variables to factors
pData(geneSetObj)[["slide"]]<-factor(pData(geneSetObj)[["slide_name"]])
pData(target_Data)$testRegion<-factor(pData(target_Data)$ANN3, unique(count_mat$ANN3))

lmm_ssgsea_results <- c()

mixedOutmc <-
  mixedModelDE(geneSetObj,
               elt = "exprs",
               modelFormula = ~ testRegion + (1 + testRegion | slide),
               groupVar = "testRegion",
               nCores = parallel::detectCores(),
               multiCore = FALSE)

# format results as data.frame
r_ssgsea_test <- do.call(rbind, mixedOutmc["lsmeans", ])
ssgsea_tests <- rownames(r_ssgsea_test)
r_ssgsea_test <- as.data.frame(r_ssgsea_test)
r_ssgsea_test$Contrast <- ssgsea_tests
#r_ssgsea_test$Genes <- msigdbr_list seems unreliable as gsva omits pathways if genes are not in data..

# use lapply in case you have multiple levels of your test factor to
# correctly associate gene name with it's row in the results table
r_ssgsea_test$Pathway <-
  unlist(lapply(colnames(mixedOutmc),
                rep, nrow(mixedOutmc["lsmeans", ][[1]])))


r_ssgsea_test$FDR <- p.adjust(r_ssgsea_test$`Pr(>|t|)`, method = "fdr")
r_ssgsea_test <- r_ssgsea_test[, c("Pathway", "Contrast", "Estimate",
                                   "Pr(>|t|)", "FDR")]
lmm_ssgsea_results <- rbind(lmm_ssgsea_results, r_ssgsea_test)
lmm_ssgsea_results <- merge(lmm_ssgsea_results, pw_gene_df)
```

## DKD - normal

```{r LMM_of_pathway_analisis class}
# # convert test variables to factors
pData(geneSetObj)[["slide"]]<-factor(pData(geneSetObj)[["slide_name"]])
pData(target_Data)$testClass<-factor(pData(target_Data)$ANN1, unique(count_mat$ANN1))

lmm_ssgsea_results_d <- c()

mixedOutmc <-
  mixedModelDE(geneSetObj,
               elt = "exprs",
               modelFormula = ~ testClass + (1 | slide),
               groupVar = "testClass",
               nCores = parallel::detectCores(),
               multiCore = FALSE)

# format results as data.frame
r_ssgsea_test <- do.call(rbind, mixedOutmc["lsmeans", ])
ssgsea_tests <- rownames(r_ssgsea_test)
r_ssgsea_test <- as.data.frame(r_ssgsea_test)
r_ssgsea_test$Contrast <- ssgsea_tests
#r_ssgsea_test$Genes <- msigdbr_list seems unreliable as gsva omits pathways if genes are not in data..

# use lapply in case you have multiple levels of your test factor to
# correctly associate gene name with it's row in the results table
r_ssgsea_test$Pathway <-
  unlist(lapply(colnames(mixedOutmc),
                rep, nrow(mixedOutmc["lsmeans", ][[1]])))


r_ssgsea_test$FDR <- p.adjust(r_ssgsea_test$`Pr(>|t|)`, method = "fdr")
r_ssgsea_test <- r_ssgsea_test[, c("Pathway", "Contrast", "Estimate",
                                   "Pr(>|t|)", "FDR")]
lmm_ssgsea_results_d <- rbind(lmm_ssgsea_results_d, r_ssgsea_test)
lmm_ssgsea_results_d <- merge(lmm_ssgsea_results_d, pw_gene_df)
```

# 8.2.1 Table of Differental analysis of pathways

## glomerulus - tubule

```{r table_of_LMM_pathway_results region, fig.width=20,fig.height=20}
datatable(subset(lmm_ssgsea_results), rownames = FALSE,
          extensions = 'Buttons', options = list (
             pageLength = 10,
              dom = 'Bftrip',
              buttons = c('copy', 'csv', 'excel', 'pdf', 'print')
            ),
          caption = "DE results for Pathways",filter='top') %>% formatRound(columns=c("Estimate","Pr(>|t|)","FDR"), digits=5)
```

## DKD - normal

```{r table_of_LMM_pathway_results class, fig.width=20,fig.height=20}
datatable(subset(lmm_ssgsea_results_d), rownames = FALSE,
          extensions = 'Buttons', options = list (
             pageLength = 10,
              dom = 'Bftrip',
              buttons = c('copy', 'csv', 'excel', 'pdf', 'print')
            ),
          caption = "DE results for Pathways",filter='top') %>% formatRound(columns=c("Estimate","Pr(>|t|)","FDR"), digits=5)
```

# 8.3 Vulcanoplot of LMM_Pathways

```{r lmm_pw_vulcano, fig.width=20,fig.height=10}
# Categorize Results based on P-value & FDR for plotting
fc_threshold = 0.5

lmm_ssgsea_results$Color <- "NS or FC < 0.3"
lmm_ssgsea_results$Color[lmm_ssgsea_results$`Pr(>|t|)` < 0.05] <- "P < 0.05"
lmm_ssgsea_results$Color[lmm_ssgsea_results$FDR < 0.05] <- "FDR < 0.05"
lmm_ssgsea_results$Color[lmm_ssgsea_results$FDR < 0.001] <- "FDR < 0.001"
lmm_ssgsea_results$Color[abs(lmm_ssgsea_results$Estimate) < fc_threshold] <- "NS or FC < 0.3"
lmm_ssgsea_results$Color <- factor(lmm_ssgsea_results$Color,
                        levels = c("NS or FC < 0.3", "P < 0.05",
                                   "FDR < 0.05", "FDR < 0.001"))

# pick top pw for either side of volcano to label
# order pw for convenience:
lmm_ssgsea_results$invert_P <- (-log10(lmm_ssgsea_results$`Pr(>|t|)`)) * sign(lmm_ssgsea_results$Estimate)
top_ssgsea_g <- c()

#loop here over tested conditions if applicable
top_ssgsea_g <- c(top_ssgsea_g,
           lmm_ssgsea_results[, 'Pathway'][
               order(lmm_ssgsea_results[, 'invert_P'], decreasing = TRUE)[1:20]],
           lmm_ssgsea_results[, 'Pathway'][
               order(lmm_ssgsea_results[, 'invert_P'], decreasing = FALSE)[1:20]])

top_ssgsea_g <- unique(top_ssgsea_g)
lmm_ssgsea_results <- lmm_ssgsea_results[, -1*ncol(lmm_ssgsea_results)] # remove invert_P from matrix

#lmm_ssgsea_results_slice <- lmm_ssgsea_results_slice[lmm_ssgsea_results_slice$FDR < 1,]

# Graph results
print(ggplot(lmm_ssgsea_results,
       aes(x = Estimate, y = -log10(`Pr(>|t|)`),
           color = Color, label = Pathway)) +
    geom_vline(xintercept = c(0.5, -0.5), lty = "dashed") +
    geom_hline(yintercept = -log10(0.05), lty = "dashed") +
    geom_point() +
    labs(x = paste(lmm_results$Contrast, " FC"),
         y = "Significance, -log10(P)",
         color = "Significance") +
    scale_color_manual(values = c(`FDR < 0.001` = "dodgerblue",
                                  `FDR < 0.05` = "lightblue",
                                  `P < 0.05` = "orange2",
                                  `NS or FC < 0.5` = "gray"),
                       guide = guide_legend(override.aes = list(size = 4))) +
    scale_y_continuous(expand = expansion(mult = c(0,0.05))) +
    geom_text_repel(data = subset(lmm_ssgsea_results, Color == "FDR < 0.05" | Color == "FDR < 0.001"),
                   point.padding = 0.15, color = "black",size=5,
                   min.segment.length = .1, box.padding = .2, lwd = 2,
                   max.overlaps = 50) +
    theme_bw(base_size = 16) +
    theme(legend.position = "bottom"))

#    +facet_wrap(~Subset, scales = "free_y"))
```

# 8.4 heatmap of pathways

```{r pw_heatmap, fig.width=20,fig.height=20}
  active_pw<-filter(lmm_ssgsea_results, `Pr(>|t|)` < 0.001)$Pathway
  active_pw<-filter(lmm_ssgsea_results, FDR < 0.001 )$Pathway
  #active_pw<-filter(lmm_ssgsea_results, Color == "FDR < 0.001")$Pathway
  
  
  active_pw<-top_ssgsea_g
  
  if (length(active_pw)>1) {
  
    print("go")
    
  pw_matrix<-assayDataElement(geneSetObj, elt = "exprs")

  pheatmap(pw_matrix[active_pw,],
         scale = "row",
         show_rownames = TRUE, show_colnames = TRUE,
         fontsize_row = 10,
         border_color = NA,
         clustering_method = "average",
         #clustering_distance_rows = "correlation",
         clustering_distance_cols = "euclidean",
         cutree_cols = 2, cutree_rows = 2,
         breaks = seq(-3, 3, 0.05),
         #color = colorRampPalette(c("purple3", "black", "yellow2"))(120),
         main = "Heatmap of selected Pathways",
         annotation_colors = color_list,
         annotation_col = pData(target_Data)[, ann_names])
  
  }else{
    print("No significant results to display")
  }
```

# 9 Spatial Deconvolution

## 9.1 Calculate backgrounds

```{r spatial_decon_bg}
bg = derive_GeoMx_background(
  norm = assayDataElement(target_Data , elt = "q_norm"),
  probepool = fData(target_Data)$Module,
  negnames = c("NegProbe-CTP01","NegProbe-Kilo","Negative Probe", "NegProbe-WTX" ))
  #negnames = "NegProbe-WTX")

```

## 9.2 Load cell profile

A "cell profile matrix" is a pre-defined matrix that specifies the
expected expression profiles of each cell type in the experiment. The
SpatialDecon library comes with one such matrix pre-loaded, the
"SafeTME" matrix, designed for estimation of immune and stroma cells in
the tumor microenvironment. (This matrix was designed to avoid genes
commonly expressed by cancer cells; see the SpatialDecon manuscript for
details.). Otherwise, load specific profiles from
<https://github.com/Nanostring-Biostats/CellProfileLibrary/tree/NewProfileMatrices>

```{r load_cell_profiles}
#safeTME
data("safeTME")
data("safeTME.matches")
current_cell_profile<-safeTME

#see: https://github.com/Nanostring-Biostats/CellProfileLibrary/tree/NewProfileMatrices

# current_cell_profile <- download_profile_matrix(species = "Human",
#                                        age_group = "Adult",
#                                        matrixname = "Bladder_MCA")

heatmap(sweep(current_cell_profile, 1, apply(current_cell_profile, 1, max), "/"),
        labRow = NA, margins = c(10, 5), cexCol = 0.7)
```

# 9.3 Run spatial deconvolution

```{r spatial_decon_run}
# vector identifying pure tumor segments:
#target_Data$istumor = target_Data$ANN3 == "CORE" & target_Data$ANN1 == "PanCK+"

res = runspatialdecon(object = target_Data,
                      norm_elt = "q_norm",
                      raw_elt = "exprs",
                      #is_pure_tumor = target_Data$istumor,
                      cell_counts = target_Data$nuclei,
                      X = current_cell_profile,
                      cellmerges = safeTME.matches,              # safeTME.matches object, used by default
                      #n_tumor_clusters = 5,                      # how many distinct tumor profiles to append to safeTME
                      align_genes = TRUE)


```

# 9.3.1 Spatial deconvolution heatmaps {.tabset .tabset-pills}

## Abundance

```{r spatial_decon_heatmap, fig.width=25,fig.height=15}
# NOTE: check clustering.. why different?

#set display thresholds
thresh <- signif(quantile(res$beta, 0.97), 2)

# plot stored to keep clustering for later
p1<-pheatmap(pmin(t(res$beta),thresh),
         #scale = "row", 
         cutree_cols = 3,
         cutree_rows = 2,
         fontsize_row = 12,
         show_rownames = TRUE, show_colnames = TRUE,
         angle_col = "90",
         border_color = NA,
         #clustering_method = "average",
         #clustering_distance_rows = "correlation",
         #clustering_distance_cols = "correlation",
         legend_breaks = c(round(seq(0, thresh, length.out = 5))[-5], thresh),
         legend_labels = c(round(seq(0, thresh, length.out = 5))[-5], paste0("Abundance scores,\ntruncated above at ", thresh)),
         #breaks = seq(0, 5, 1),
         color = colorRampPalette(c("white","darkblue"))(100),
         annotation_colors = color_list,
         annotation_col = pData(target_Data)[, ann_names]
         )
#p1
```

## Proportional

```{r spatial_decon_propheatmap, fig.width=25,fig.height=15}
# proportions:
props <- replace(res$prop_of_nontumor, is.na(res$prop_of_nontumor), 0)

p2<-pheatmap(t(props),
         #scale = "row", 
         cutree_cols = 3,
         cutree_rows = 2,
         fontsize_row = 12,
         show_rownames = TRUE, show_colnames = TRUE,
         angle_col = "90",
         border_color = NA,
         #clustering_method = "average",
         #clustering_distance_rows = "correlation",
         #clustering_distance_cols = "correlation",
         legend_breaks = round(seq(0, max(props) * 0.99, length.out = 5), 2),
         legend_labels = c(round(seq(0, max(props), length.out = 5), 2)[-5], "Proportion of all\nfitted populations"),
         color = colorRampPalette(c("white","darkblue"))(100),
         annotation_colors = color_list,
         annotation_col = pData(target_Data)[, ann_names])

#p2

```

## Scaled

```{r spatial_decon_scaledheatmap, fig.width=25,fig.height=15}
# scaled abundances:
epsilon <- min(res$beta[res$beta > 0])
mat <- sweep(res$beta, 1, pmax(apply(res$beta, 1, max), epsilon), "/")

pheatmap(t(mat),
         #scale = "row",
         cutree_cols = 3,
         cutree_rows = 3,
         fontsize_row = 12,
         show_rownames = TRUE, show_colnames = TRUE,
         angle_col = "90",
         border_color = NA,
         #clustering_method = "average",
         #clustering_distance_rows = "correlation",
         #clustering_distance_cols = "correlation",
         legend_breaks = c(round(seq(0, 1, length.out = 5), 2)[-5], 1),
         legend_labels = c(round(seq(0, 1, length.out = 5), 2)[-5], "Scaled abundance\n(ratio to max)"),
         color = colorRampPalette(c("white","darkblue"))(100),
         annotation_colors = color_list,
         annotation_col = pData(target_Data)[, ann_names])

```

# 9.4 Barplots {.tabset .tabset-pills}

## abundance

```{r SD_abundance_barplot, fig.width=25,fig.height=15}
# define variables to show in heatmaps:
variables_to_plot <- c("slide_name", "region", "class")

col <- cellcols

layout(matrix(c(1, 2, 3, 3), nrow = 2),
       widths = c(10, 3, 10, 3),
       heights = c(1, 8, 10),
      )

par(mar = c(0, 8.2, 0, 0.2))
plot(p1$tree_col, labels = F, main = "", ylab = "", yaxt = "n")
par(mar = c(15, 8, 0, 0))

# data to plot:
mat <- t(res$beta)[, p1$tree_col$order]
# infer scale of negative y-axis for annotation colorbars
ymin <- -max(colSums(mat)) * 0.15
if (!is.finite(ymin)) {
  ymin <- 0
}

# draw barplot:
bp <- barplot(mat,
              cex.lab = 1.5,
              col = col, border = NA,
              cex.names = 1.1,
              las = 2, main = "", ylab = "Abundance scores",
              ylim = c(ymin, max(colSums(mat)))
)


# add color bars for annotations
for (name in rev(variables_to_plot)) {
  yrange <- seq(ymin / 3, ymin, length.out = length(variables_to_plot) + 1)[match(name, variables_to_plot) + c(0, 1)]
  xwidth <- (bp[2] - bp[1]) / 2
  for (i in 1:ncol(mat)) {
    rect(bp[i] - xwidth, yrange[2], bp[i] + xwidth, yrange[1],
         # border = NA, col = ann_colors[[name]][segmentAnnotations[match(colnames(mat)[i], segmentAnnotations$segmentID), name]]
         #border = NA, col = ann_colors[[name]][ann[p1$tree_col$order[i], name]]
         border = NA, col = color_list[[name]][ann[colnames(mat)[i], name]]
    )
  }
}
axis(2,
     at = seq(ymin / 3, ymin, length.out = length(variables_to_plot) + 2)[-c(1, length(variables_to_plot) + 2)],
     las = 2, labels = variables_to_plot, lty = 0, cex.axis = 1.2
)

#draw a legend:
par(mar = c(0.1, 0.1, 0.1, 0.1))
frame()
legendcols <- legendnames <- c()
#for (name in rev(names(ann_colors))) {
for (name in c("slide_name", "region","class")) {
  legendcols <- c(legendcols, NA, color_list[[name]], NA)
  legendnames <- c(legendnames, name, names(color_list[[name]]), NA)
}
legend("center",
       pch = 15,
       cex = 1.5,
       col = c(legendcols, rep(NA, 1), rev(col)),
       legend = c(legendnames, "Cell type", rev(names(col))),
)
```

## proportional

```{r SD_prop_barplot, fig.width=25,fig.height=15}
# define variables to show in heatmaps:
variables_to_plot <- c("slide name", "segment","pheno")

layout(matrix(c(1, 2, 3, 3), nrow = 2),
       widths = c(10, 3, 10, 3),
       heights = c(1, 8, 10),
      )

par(mar = c(0, 8.2, 0, 0.2))
plot(p2$tree_col, labels = F, main = "", ylab = "", yaxt = "n")
par(mar = c(15, 8, 0, 0))

# data to plot:
mat <- t(res$prop_of_nontumor)[, p2$tree_col$order]
  mat <- replace(mat, is.na(mat), 0)
  # infer scale of negative y-axis for annotation colorbars
  ymin <- -0.15

# draw barplot:
bp <- barplot(mat,
              cex.lab = 1.5,
              col = col, border = NA,
              cex.names = 1.1,
              las = 2, main = "", ylab = "Proportion of fitted cells",
              ylim = c(ymin, max(colSums(mat)))
)

# add color bars for annotations
for (name in rev(variables_to_plot)) {
  yrange <- seq(ymin / 3, ymin, length.out = length(variables_to_plot) + 1)[match(name, variables_to_plot) + c(0, 1)]
  xwidth <- (bp[2] - bp[1]) / 2
  for (i in 1:ncol(mat)) {
    rect(bp[i] - xwidth, yrange[2], bp[i] + xwidth, yrange[1],
         # border = NA, col = ann_colors[[name]][segmentAnnotations[match(colnames(mat)[i], segmentAnnotations$segmentID), name]]
         #border = NA, col = ann_colors[[name]][ann[p2$tree_col$order[i], name]]
         border = NA, col = color_list[[name]][ann[colnames(mat)[i], name]]
    )
  }
}
axis(2,
     at = seq(ymin / 3, ymin, length.out = length(variables_to_plot) + 2)[-c(1, length(variables_to_plot) + 2)],
     las = 2, labels = variables_to_plot, lty = 0, cex.axis = 1.2
)


#draw a legend:
par(mar = c(0.1, 0.1, 0.1, 0.1))
frame()
legendcols <- legendnames <- c()
#for (name in rev(names(ann_colors))) {
for (name in c("slide name", "segment","pheno")) {
  legendcols <- c(legendcols, NA, color_list[[name]], NA)
  legendnames <- c(legendnames, name, names(color_list[[name]]), NA)
}
legend("center",
       pch = 15,
       cex = 1.4,
       col = c(legendcols, rep(NA, 1), rev(col)),
       legend = c(legendnames, "Cell type", rev(names(col))),
)
```

# 10 Code & Versions

Pipelineversion: v1 based on:
<https://bioconductor.org/packages/devel/workflows/vignettes/GeoMxWorkflows/inst/doc/GeomxTools_RNA-NGS_Analysis.html>

The underlying code can be downloaded from the 'Code', button on the top
of this page. Choose option 'download Rmd' to download the full pipeline
which can be opened in R or Rstudio. Some filepaths are hardcoded and
need to be changed according to your setup.

# 10.1 R session information

```{r session_info}
sessionInfo()
```

## 10.2 References

![](C:/Users/pkloosterman/Documents/general_workflow/decoration-stroke-flat-v2.png)

```{r}
knitr::knit_exit()
```

```{r}
knitr::knit_exit()
```

# 9.0 reload data

```{r spatial_decon_prepare}
#reload data
# Data <-
#   readNanoStringGeoMxSet(dccFiles = DCCFiles,
#                          pkcFiles = PKCFiles,
#                          phenoDataFile = SampleAnnotationFile,
#                          phenoDataSheet = "Sheet1",
#                          phenoDataDccColName = "Sample_ID",
#                          protocolDataColNames = c("aoi", "roi"),
#                          experimentDataColNames = c("panel"))
# 
# pkcs <- annotation(Data)
# modules <- gsub(".pkc", "", pkcs)
# 
# #shift any expression counts with a value of 0 to 1 to enable in downstream transformations.
# Data <- shiftCountsOne(Data, useDALogic = TRUE)
# 
# #collaps_targets
# target_Data <- aggregateCounts(Data)
# dim(target_Data)
# 
# #normalize
# target_Data <- normalize(target_Data , data_type = "RNA",
#                              norm_method = "quant", 
#                              desiredQuantile = .75,
#                              toElt = "q_norm")
```

# 9.4 Run advanced spatial devoncolution

```{r}
# vector identifying pure tumor segments:
target_Data$istumor = target_Data$ANN2 == "Epithelium"

# run spatialdecon with all the bells and whistles:
restils = runspatialdecon(object = target_Data,
                          norm_elt = "q_norm",                    # normalized data
                          raw_elt = "exprs",                      # expected background counts for every data point in norm
                          X = safeTME,                            # safeTME matrix, used by default
                          cellmerges = safeTME.matches,           # safeTME.matches object, used by default
                          cell_counts = target_Data$nuclei,      # nuclei counts, used to estimate total cells
                          is_pure_tumor = target_Data$istumor,   # identities of the Tumor segments/observations
                          n_tumor_clusters = 5)                   # how many distinct tumor profiles to append to safeTME

#str(pData(restils))
heatmap(sweep(restils@experimentData@other$SpatialDeconMatrix, 1, apply(restils@experimentData@other$SpatialDeconMatrix, 1, max), "/"),
         labRow = NA, margins = c(10, 5))

```

# 9.3.2 Plotting deconvolution results

```{r, fig.width=15,fig.height=7}
# For reference, show the TILs color data object used by the plotting functions 
# when safeTME has been used:
data("cellcols")
cellcols

o = hclust(dist(t(res$cell.counts$cell.counts)))$order
layout(matrix(c(1, 2), 1), widths = c(7, 3))
TIL_barplot(t(res$cell.counts$cell.counts[, o]),
            horiz = TRUE, draw_legend = TRUE, cex.names = 0.9)

#par(mar=c(2, 15, 2, 2))

# or the proportions of cells:
temp = replace(res$prop_of_nontumor, is.na(res$prop_of_nontumor), 0)
o = hclust(dist(temp[res$ANN2 == "CD45",]))$order
TIL_barplot(t(res$prop_of_all), 
            horiz = TRUE, draw_legend = TRUE, cex.names = 0.9)

```

# 9.3.3 Florets of Spatial deconvolution

The second function is "florets", used for plotting cell abundances atop
some 2-D projection. Here, we'll plot cell abundances atop the first 2
principal components of the data:

```{r}

#NOTE: seems to crash if all assignments are zeros in an AOI?

# PCA of the normalized data:
norm=assayDataElement(target_Data,elt="q_norm")
pc = prcomp(t(log2(pmax(norm, 1))))$x[, c(1, 2)]

# 
# # run florets function:
par(mar = c(5,5,1,1))
layout(matrix(c(1, 2), 1), widths = c(6, 2))
florets(x = pc[1:14, 1], y = pc[1:14, 2], b = t(res$beta)[1:14,], cex = 2, xlab = "PC1", ylab = "PC2")
par(mar = c(0,0,0,0))
frame()
legend("center", fill = cellcols[rownames(t(res$beta))],
       legend = rownames(t(res$beta)), cex = 0.7)
```

# 9.4 combining celltypes

When two cell types are too similar, the estimation of their abundances
becomes unstable. However, their sum can still be estimated easily. The
function "collapseCellTypes" takes a deconvolution results object and
collapses any colsely-related cell types you tell it to

```{r}
matching = list()
matching$myeloid = c( "macrophages", "monocytes", "mDCs")
matching$T.NK = c("CD4.T.cells","CD8.T.cells", "Treg", "NK")
matching$B = c("B")
matching$mast = c("mast")
matching$neutrophils = c("neutrophils")
matching$stroma = c("endothelial.cells", "fibroblasts")

collapsed = collapseCellTypes(fit = restils, matching = matching)

heatmap(collapsed$beta, cexRow = 0.85, cexCol = 0.75)
```
